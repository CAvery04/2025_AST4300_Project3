{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e43b5d36-b656-4077-96e8-84590f6b140d",
   "metadata": {},
   "source": [
    "# Milky Way Mapper's Galaxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8ff0b",
   "metadata": {},
   "source": [
    "## Section 7: Paper Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d457f8-beb0-4f9c-9886-de9ecdcf08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some things\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7525f7b4-27eb-4abd-87c3-916ab17aef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the data (may have to change this for wherever you downloaded your file)\n",
    "#in google colab you can get the file using\n",
    "#!wget https://dr19.sdss.org/sas/dr19/spectro/astra/0.6.0/summary/astraAllStarASPCAP-0.6.0.fits.gz \n",
    "\n",
    "filename='astraAllStarASPCAP-0.6.0.fits'\n",
    "tb = fits.open(filename)\n",
    "header=tb[2].header\n",
    "data = tb[2].data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f63592d-5b8d-4c71-b64b-9001481db68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "good=np.where((data['teff'] > 3700) & (data['teff'] < 5300) &\n",
    "               (data['logg'] > 0.9) & (data['logg'] < 3.3) &\n",
    "               (data['m_h_atm'] > -2.0) & (data['m_h_atm'] < 0.6) &   \n",
    "               (data['flag_bad']==False) )\n",
    "\n",
    "data_masked=data[good]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69c238-4e3a-49a3-a0e1-c945d4e3cb26",
   "metadata": {},
   "source": [
    "## Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e198e51e-627e-43a1-aca4-4b421a89b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESS\n",
    "# tessraw = Table.read(\"Theodoridis2025.csv\", format=\"ascii\")\n",
    "# #this one has an age column in Gyr already so we're just going to rename it Age\n",
    "# tessraw['Final_age'].name='Age'\n",
    "# hasagetess=np.where((tessraw['Age']==tessraw['Age']) & (tessraw['Age']>0.1) &(tessraw['Flag']==0))\n",
    "# tess=tessraw[hasagetess]\n",
    "# tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c979c407-4098-406d-9ef0-b322b985bc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=6529</i>\n",
       "<table id=\"table2535792501408\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>KIC</th><th>2MASS</th><th>Teff</th><th>e_Teff</th><th>FeH</th><th>e_FeH</th><th>AFe</th><th>e_AFe</th><th>Nmax</th><th>e_Nmax</th><th>Dnu</th><th>e_Dnu</th><th>ES</th><th>Fdnu</th><th>e_Fdnu</th><th>M(cor)</th><th>e_M(cor)-ran</th><th>e_M(cor)-sys</th><th>R(cor)</th><th>e_R(cor)-ran</th><th>e_R(cor)-sys</th><th>logg(seis)</th><th>e_logg(seis)-ran</th><th>e_logg(seis)-sys</th><th>Rho</th><th>e_Rho-ran</th><th>e_Rho-sys</th><th>LogAge</th><th>E_LogAge</th><th>e_LogAge</th><th>Av</th><th>e_Av</th><th>Notes</th><th>Age</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th>K</th><th>K</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>uHz</th><th></th><th>uHz</th><th></th><th></th><th></th><th></th><th>Msun</th><th></th><th></th><th>Rsun</th><th></th><th></th><th>dex(cm / s2)</th><th></th><th></th><th>g / cm3</th><th></th><th></th><th>Myr</th><th>Myr</th><th>Myr</th><th>mag</th><th>mag</th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>str18</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str8</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str18</th><th>float64</th></tr></thead>\n",
       "<tr><td>1027110</td><td>2M19250937+3644599</td><td>4177.6</td><td>51.8</td><td>-0.232</td><td>0.025</td><td>0.205</td><td>0.015</td><td>6.496</td><td>0.015</td><td>1.132</td><td>0.029</td><td>RGB</td><td>1.0458</td><td>0.0006</td><td>0.985</td><td>0.126</td><td>0.044</td><td>23.412</td><td>0.06</td><td>0.017</td><td>1.692</td><td>0.007</td><td>0.007</td><td>0.0001082</td><td>0.058</td><td>0.008</td><td>4.002</td><td>0.205</td><td>-0.189</td><td>0.269</td><td>0.121</td><td>SeisUnc</td><td>10.046157902783946</td></tr>\n",
       "<tr><td>1027337</td><td>2M19252021+3647118</td><td>4636.0</td><td>67.3</td><td>0.275</td><td>0.024</td><td>0.023</td><td>0.01</td><td>73.975</td><td>0.009</td><td>6.991</td><td>0.013</td><td>RGB</td><td>1.0333</td><td>0.0003</td><td>1.227</td><td>0.063</td><td>0.038</td><td>7.544</td><td>0.029</td><td>0.014</td><td>2.772</td><td>0.005</td><td>0.007</td><td>0.004029</td><td>0.026</td><td>0.007</td><td>3.798</td><td>0.099</td><td>-0.09</td><td>0.214</td><td>0.071</td><td>...</td><td>6.2805835881331795</td></tr>\n",
       "<tr><td>1160789</td><td>2M19233280+3652207</td><td>4729.6</td><td>72.3</td><td>-0.257</td><td>0.034</td><td>0.188</td><td>0.015</td><td>25.209</td><td>0.015</td><td>3.545</td><td>0.011</td><td>RC</td><td>0.9965</td><td>0.0324</td><td>0.875</td><td>0.147</td><td>0.082</td><td>10.86</td><td>0.071</td><td>0.025</td><td>2.308</td><td>0.007</td><td>0.01</td><td>0.0009635</td><td>0.069</td><td>0.008</td><td>3.889</td><td>0.133</td><td>-0.146</td><td>0.009</td><td>0.074</td><td>...</td><td>7.744617978025183</td></tr>\n",
       "<tr><td>1161447</td><td>2M19241746+3651460</td><td>4776.1</td><td>86.2</td><td>0.058</td><td>0.029</td><td>-0.006</td><td>0.013</td><td>37.066</td><td>0.027</td><td>4.153</td><td>0.011</td><td>RC</td><td>1.003</td><td>0.0238</td><td>1.46</td><td>0.135</td><td>0.076</td><td>11.54</td><td>0.059</td><td>0.022</td><td>2.478</td><td>0.012</td><td>0.01</td><td>0.00134</td><td>0.052</td><td>0.008</td><td>3.396</td><td>0.166</td><td>-0.145</td><td>0.4</td><td>0.086</td><td>...</td><td>2.48885731828239</td></tr>\n",
       "<tr><td>1161618</td><td>2M19242614+3648478</td><td>4742.0</td><td>72.1</td><td>0.064</td><td>0.029</td><td>0.005</td><td>0.012</td><td>33.926</td><td>0.01</td><td>4.093</td><td>0.012</td><td>RC</td><td>1.001</td><td>0.0033</td><td>1.183</td><td>0.063</td><td>0.077</td><td>10.879</td><td>0.028</td><td>0.023</td><td>2.438</td><td>0.005</td><td>0.01</td><td>0.001296</td><td>0.026</td><td>0.008</td><td>3.639</td><td>0.064</td><td>-0.069</td><td>0.199</td><td>0.074</td><td>...</td><td>4.355118736855684</td></tr>\n",
       "<tr><td>1162220</td><td>2M19245791+3653298</td><td>4190.1</td><td>51.7</td><td>0.083</td><td>0.021</td><td>0.07</td><td>0.011</td><td>11.0</td><td>0.01</td><td>1.669</td><td>0.011</td><td>RGB</td><td>1.0484</td><td>0.0004</td><td>1.007</td><td>0.055</td><td>0.044</td><td>18.175</td><td>0.024</td><td>0.017</td><td>1.922</td><td>0.005</td><td>0.007</td><td>0.0002364</td><td>0.021</td><td>0.008</td><td>4.056</td><td>0.087</td><td>-0.083</td><td>0.181</td><td>0.073</td><td>...</td><td>11.37627285823431</td></tr>\n",
       "<tr><td>1162746</td><td>2M19252639+3649116</td><td>4798.1</td><td>75.6</td><td>-0.388</td><td>0.038</td><td>0.229</td><td>0.017</td><td>27.798</td><td>0.015</td><td>3.763</td><td>0.01</td><td>RC</td><td>0.9972</td><td>0.0281</td><td>0.941</td><td>0.131</td><td>0.08</td><td>10.688</td><td>0.062</td><td>0.024</td><td>2.354</td><td>0.007</td><td>0.01</td><td>0.001087</td><td>0.06</td><td>0.008</td><td>3.786</td><td>0.139</td><td>-0.131</td><td>0.172</td><td>0.075</td><td>...</td><td>6.109420249055721</td></tr>\n",
       "<tr><td>1163114</td><td>2M19254564+3650475</td><td>4285.8</td><td>54.4</td><td>0.297</td><td>0.02</td><td>0.025</td><td>0.01</td><td>14.356</td><td>0.011</td><td>1.887</td><td>0.008</td><td>RGB</td><td>1.0396</td><td>0.0004</td><td>1.467</td><td>0.05</td><td>0.043</td><td>19.097</td><td>0.021</td><td>0.016</td><td>2.042</td><td>0.006</td><td>0.007</td><td>0.0002971</td><td>0.016</td><td>0.008</td><td>3.538</td><td>0.079</td><td>-0.077</td><td>0.382</td><td>0.069</td><td>...</td><td>3.451437393358561</td></tr>\n",
       "<tr><td>1163359</td><td>2M19255838+3650557</td><td>4571.9</td><td>71.0</td><td>-0.339</td><td>0.032</td><td>0.218</td><td>0.017</td><td>21.468</td><td>0.009</td><td>2.632</td><td>0.009</td><td>RGB</td><td>1.0346</td><td>0.0005</td><td>1.454</td><td>0.051</td><td>0.043</td><td>15.297</td><td>0.022</td><td>0.016</td><td>2.231</td><td>0.005</td><td>0.007</td><td>0.0005725</td><td>0.018</td><td>0.008</td><td>3.376</td><td>0.075</td><td>-0.072</td><td>0.195</td><td>0.076</td><td>...</td><td>2.3768402866248763</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>12735106</td><td>2M19172948+5156326</td><td>4648.1</td><td>67.9</td><td>0.193</td><td>0.026</td><td>0.02</td><td>0.01</td><td>33.407</td><td>0.018</td><td>4.049</td><td>0.016</td><td>RC</td><td>1.0033</td><td>0.0073</td><td>1.135</td><td>0.09</td><td>0.078</td><td>10.79</td><td>0.04</td><td>0.023</td><td>2.427</td><td>0.008</td><td>0.01</td><td>0.001274</td><td>0.035</td><td>0.008</td><td>3.711</td><td>0.096</td><td>-0.088</td><td>0.202</td><td>0.073</td><td>...</td><td>5.140436515824259</td></tr>\n",
       "<tr><td>12735291</td><td>2M19175256+5154430</td><td>4718.4</td><td>82.0</td><td>-0.088</td><td>0.03</td><td>0.106</td><td>0.014</td><td>30.239</td><td>0.009</td><td>3.996</td><td>0.012</td><td>RC</td><td>0.9992</td><td>0.0092</td><td>0.922</td><td>0.07</td><td>0.079</td><td>10.186</td><td>0.032</td><td>0.024</td><td>2.387</td><td>0.006</td><td>0.01</td><td>0.001231</td><td>0.03</td><td>0.008</td><td>3.869</td><td>0.068</td><td>-0.07</td><td>0.152</td><td>0.084</td><td>...</td><td>7.396052750582382</td></tr>\n",
       "<tr><td>12735851</td><td>2M19192010+5158343</td><td>4706.3</td><td>71.7</td><td>-0.25</td><td>0.034</td><td>0.065</td><td>0.015</td><td>42.809</td><td>0.009</td><td>4.775</td><td>0.006</td><td>RGB</td><td>1.0371</td><td>0.001</td><td>1.101</td><td>0.043</td><td>0.041</td><td>9.36</td><td>0.017</td><td>0.015</td><td>2.537</td><td>0.005</td><td>0.007</td><td>0.001893</td><td>0.012</td><td>0.007</td><td>3.805</td><td>0.069</td><td>-0.065</td><td>0.165</td><td>0.073</td><td>...</td><td>6.382634861905489</td></tr>\n",
       "<tr><td>12736410</td><td>2M19203116+5156352</td><td>4800.7</td><td>75.0</td><td>-0.042</td><td>0.032</td><td>0.044</td><td>0.013</td><td>32.015</td><td>0.012</td><td>3.956</td><td>0.017</td><td>RC</td><td>0.9963</td><td>0.0225</td><td>1.183</td><td>0.12</td><td>0.078</td><td>11.163</td><td>0.058</td><td>0.023</td><td>2.415</td><td>0.006</td><td>0.01</td><td>0.001199</td><td>0.056</td><td>0.008</td><td>3.616</td><td>0.133</td><td>-0.128</td><td>0.241</td><td>0.076</td><td>...</td><td>4.130475019901614</td></tr>\n",
       "<tr><td>12784948</td><td>2M19210624+5200236</td><td>4956.6</td><td>83.2</td><td>-0.381</td><td>0.042</td><td>0.092</td><td>0.016</td><td>34.03</td><td>0.009</td><td>4.17</td><td>0.015</td><td>RC</td><td>0.9867</td><td>0.0219</td><td>1.254</td><td>0.114</td><td>0.077</td><td>11.061</td><td>0.055</td><td>0.023</td><td>2.449</td><td>0.005</td><td>0.01</td><td>0.001307</td><td>0.054</td><td>0.008</td><td>3.476</td><td>0.143</td><td>-0.127</td><td>0.217</td><td>0.079</td><td>...</td><td>2.992264636608189</td></tr>\n",
       "<tr><td>12785083</td><td>2M19212376+5204593</td><td>4689.1</td><td>70.0</td><td>-0.001</td><td>0.029</td><td>0.083</td><td>0.012</td><td>28.558</td><td>0.019</td><td>3.618</td><td>0.016</td><td>RC</td><td>0.9973</td><td>0.0399</td><td>1.154</td><td>0.183</td><td>0.08</td><td>11.742</td><td>0.088</td><td>0.024</td><td>2.361</td><td>0.009</td><td>0.01</td><td>0.001005</td><td>0.086</td><td>0.008</td><td>3.645</td><td>0.207</td><td>-0.192</td><td>0.17</td><td>0.074</td><td>...</td><td>4.4157044735331255</td></tr>\n",
       "<tr><td>12785250</td><td>2M19214766+5205365</td><td>4764.1</td><td>85.4</td><td>-0.312</td><td>0.035</td><td>0.031</td><td>0.017</td><td>32.908</td><td>0.015</td><td>3.85</td><td>0.004</td><td>RC(S)</td><td>1.0015</td><td>0.0216</td><td>1.386</td><td>0.102</td><td>0.078</td><td>11.942</td><td>0.047</td><td>0.023</td><td>2.426</td><td>0.008</td><td>0.01</td><td>0.001148</td><td>0.044</td><td>0.008</td><td>3.368</td><td>0.128</td><td>-0.113</td><td>0.272</td><td>0.085</td><td>...</td><td>2.3334580622810024</td></tr>\n",
       "<tr><td>12884116</td><td>2M19182431+5215519</td><td>4642.0</td><td>68.0</td><td>0.008</td><td>0.028</td><td>0.047</td><td>0.012</td><td>50.54</td><td>0.009</td><td>5.402</td><td>0.004</td><td>RGB</td><td>1.0378</td><td>0.001</td><td>1.081</td><td>0.039</td><td>0.04</td><td>8.563</td><td>0.014</td><td>0.015</td><td>2.606</td><td>0.005</td><td>0.007</td><td>0.002427</td><td>0.008</td><td>0.007</td><td>3.935</td><td>0.066</td><td>-0.064</td><td>0.303</td><td>0.071</td><td>...</td><td>8.609937521846009</td></tr>\n",
       "<tr><td>12884930</td><td>2M19200187+5214588</td><td>4913.6</td><td>89.4</td><td>-0.079</td><td>0.034</td><td>0.011</td><td>0.014</td><td>37.999</td><td>0.009</td><td>4.385</td><td>0.015</td><td>RC</td><td>0.9988</td><td>0.0114</td><td>1.343</td><td>0.086</td><td>0.075</td><td>10.854</td><td>0.041</td><td>0.022</td><td>2.495</td><td>0.006</td><td>0.01</td><td>0.001481</td><td>0.038</td><td>0.008</td><td>3.469</td><td>0.097</td><td>-0.103</td><td>0.315</td><td>0.086</td><td>...</td><td>2.9444216337987603</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=6529>\n",
       "  KIC          2MASS          Teff  ...   e_Av   Notes         Age        \n",
       "                               K    ...   mag                             \n",
       " int64         str18        float64 ... float64  str18       float64      \n",
       "-------- ------------------ ------- ... ------- ------- ------------------\n",
       " 1027110 2M19250937+3644599  4177.6 ...   0.121 SeisUnc 10.046157902783946\n",
       " 1027337 2M19252021+3647118  4636.0 ...   0.071     ... 6.2805835881331795\n",
       " 1160789 2M19233280+3652207  4729.6 ...   0.074     ...  7.744617978025183\n",
       " 1161447 2M19241746+3651460  4776.1 ...   0.086     ...   2.48885731828239\n",
       " 1161618 2M19242614+3648478  4742.0 ...   0.074     ...  4.355118736855684\n",
       " 1162220 2M19245791+3653298  4190.1 ...   0.073     ...  11.37627285823431\n",
       " 1162746 2M19252639+3649116  4798.1 ...   0.075     ...  6.109420249055721\n",
       " 1163114 2M19254564+3650475  4285.8 ...   0.069     ...  3.451437393358561\n",
       " 1163359 2M19255838+3650557  4571.9 ...   0.076     ... 2.3768402866248763\n",
       "     ...                ...     ... ...     ...     ...                ...\n",
       "12735106 2M19172948+5156326  4648.1 ...   0.073     ...  5.140436515824259\n",
       "12735291 2M19175256+5154430  4718.4 ...   0.084     ...  7.396052750582382\n",
       "12735851 2M19192010+5158343  4706.3 ...   0.073     ...  6.382634861905489\n",
       "12736410 2M19203116+5156352  4800.7 ...   0.076     ...  4.130475019901614\n",
       "12784948 2M19210624+5200236  4956.6 ...   0.079     ...  2.992264636608189\n",
       "12785083 2M19212376+5204593  4689.1 ...   0.074     ... 4.4157044735331255\n",
       "12785250 2M19214766+5205365  4764.1 ...   0.085     ... 2.3334580622810024\n",
       "12884116 2M19182431+5215519  4642.0 ...   0.071     ...  8.609937521846009\n",
       "12884930 2M19200187+5214588  4913.6 ...   0.086     ... 2.9444216337987603"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age option 2 APOKASC-2 Pinsonneault et al. 2018\n",
    "#Reading in the table, making sure all the tables have a column named Age in Gyr\n",
    "# and that every star in the table has an Age\n",
    "apokasc2raw = Table.read(\"Pinsonneault2018.txt\", format=\"ascii.cds\")\n",
    "apokasc2raw['Age']=(10**np.array(apokasc2raw['LogAge'])/1000.) #Age was in log(Myr) so needs converting\n",
    "hasagea2=np.where((apokasc2raw['Age']==apokasc2raw['Age']) & (apokasc2raw['Age']>0.1))\n",
    "apokasc2=apokasc2raw[hasagea2]\n",
    "apokasc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "842af861-cd4a-4cd8-8516-8a813f1531be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Age option 3 APOKASC-3 Pinsonneault et al. 2025\n",
    "# #Reading in the table, making sure all the tables have a column named Age in Gyr\n",
    "# # and that every star in the table has an Age\n",
    "# apokasc3raw= Table.read(\"Pinsonneault2025.txt\", format=\"ascii.cds\")\n",
    "# #in this case there were two age columns, one for Red Clump and one for Red Giant Branch so we combine them\n",
    "# ageRC=np.array(apokasc3raw['AgeRC']*(apokasc3raw['EvolState']=='RC'))\n",
    "# rcnans=np.isnan(ageRC) #removing nans from this version of the table.\n",
    "# ageRC[rcnans]=0\n",
    "# ageRGB=np.array(apokasc3raw['AgeRGB']*(apokasc3raw['EvolState']=='RGB'))\n",
    "# rgbnans=np.isnan(ageRGB) #removing nans from this version of the table.\n",
    "# ageRGB[rgbnans]=0\n",
    "# apokasc3raw['Age']=(ageRC+ageRGB)\n",
    "\n",
    "# hasagea3=np.where((apokasc3raw['Age']==apokasc3raw['Age']) & (apokasc3raw['Age']>0.1))\n",
    "# apokasc3=apokasc3raw[hasagea3]\n",
    "# apokasc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4214dd6-940b-4f89-9091-e33337955724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=4661</i>\n",
       "<table id=\"table2538254465216\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>EPIC</th><th>APOGEE</th><th>GaiaEDR3</th><th>RAdeg</th><th>DEdeg</th><th>GLON</th><th>GLAT</th><th>Rkpc</th><th>Zkpc</th><th>Teff</th><th>Teff-u</th><th>e_Teff</th><th>logg</th><th>logg-u</th><th>e_logg</th><th>[Fe/H]</th><th>e_[Fe/H]</th><th>[a/M]</th><th>e_[a/M]</th><th>[O/Fe]</th><th>e_[O/Fe]</th><th>aFlag</th><th>Mstar</th><th>e_Mstar</th><th>Rstar</th><th>e_Rstar</th><th>logg-seis</th><th>e_logg-seis</th><th>numax</th><th>e_numax</th><th>deltanu</th><th>e_deltanu</th><th>Age</th><th>e_Age</th><th>E_Age</th><th>Age-mode</th><th>SFW</th><th>EvState</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th></th><th>deg</th><th>deg</th><th>deg</th><th>deg</th><th>kpc</th><th>kpc</th><th>K</th><th>K</th><th>K</th><th>dex(cm / s2)</th><th>dex(cm / s2)</th><th>dex(cm / s2)</th><th>dex(Sun)</th><th>dex(Sun)</th><th>dex(Sun)</th><th>dex(Sun)</th><th>dex(Sun)</th><th>dex(Sun)</th><th></th><th>Msun</th><th>Msun</th><th>Rsun</th><th>Rsun</th><th>dex(cm / s2)</th><th>dex(cm / s2)</th><th>uHz</th><th>uHz</th><th>uHz</th><th>uHz</th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th>Gyr</th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>str18</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str6</th><th>str6</th><th>int64</th><th>int64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str6</th><th>str5</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str5</th><th>str3</th></tr></thead>\n",
       "<tr><td>211821580</td><td>2M08270102+1737253</td><td>662088729307609216</td><td>126.7543</td><td>17.6237</td><td>206.812</td><td>28.792</td><td>10.252</td><td>1.306</td><td>4795</td><td>4696</td><td>9</td><td>2.43</td><td>2.5</td><td>0.03</td><td>-0.453</td><td>0.008</td><td>0.094</td><td>0.007</td><td>0.173</td><td>0.02</td><td>0</td><td>0.92</td><td>0.08</td><td>9.5</td><td>0.26</td><td>2.45</td><td>0.01</td><td>34.4</td><td>0.9</td><td>4.42</td><td>0.01</td><td>11.3</td><td>3.0</td><td>4.1</td><td>10.8</td><td>4.32</td><td>RGB</td></tr>\n",
       "<tr><td>212434736</td><td>2M13572534-1408010</td><td>6302108283398593152</td><td>209.3556</td><td>-14.1336</td><td>326.169</td><td>45.74</td><td>7.504</td><td>0.795</td><td>4787</td><td>4705</td><td>9</td><td>2.94</td><td>2.99</td><td>0.02</td><td>-0.24</td><td>0.007</td><td>0.183</td><td>0.006</td><td>0.252</td><td>0.018</td><td>1</td><td>1.11</td><td>0.02</td><td>5.66</td><td>0.04</td><td>2.98</td><td>0.0</td><td>116.8</td><td>0.7</td><td>10.56</td><td>0.0</td><td>7.3</td><td>0.5</td><td>0.5</td><td>7.2</td><td>7.43</td><td>RGB</td></tr>\n",
       "<tr><td>212333123</td><td>2M13400342-1634554</td><td>3605202458865639552</td><td>205.0143</td><td>-16.5821</td><td>319.433</td><td>44.726</td><td>6.713</td><td>2.016</td><td>4795</td><td>4703</td><td>16</td><td>2.87</td><td>2.95</td><td>0.04</td><td>-0.383</td><td>0.014</td><td>0.235</td><td>0.011</td><td>0.312</td><td>0.036</td><td>1</td><td>0.87</td><td>0.06</td><td>5.79</td><td>0.13</td><td>2.85</td><td>0.0</td><td>87.3</td><td>0.7</td><td>9.03</td><td>0.1</td><td>16.8</td><td>4.0</td><td>5.3</td><td>17.5</td><td>5.61</td><td>RGB</td></tr>\n",
       "<tr><td>212173678</td><td>2M08253330+2334276</td><td>678233202137154304</td><td>126.3888</td><td>23.5743</td><td>200.25</td><td>30.532</td><td>9.024</td><td>0.587</td><td>4780</td><td>4701</td><td>8</td><td>2.76</td><td>2.83</td><td>0.02</td><td>-0.188</td><td>0.007</td><td>0.063</td><td>0.006</td><td>0.103</td><td>0.017</td><td>0</td><td>1.27</td><td>0.05</td><td>7.56</td><td>0.11</td><td>2.78</td><td>0.0</td><td>74.9</td><td>0.9</td><td>7.31</td><td>0.03</td><td>4.3</td><td>0.6</td><td>0.7</td><td>4.1</td><td>6.53</td><td>RGB</td></tr>\n",
       "<tr><td>213789445</td><td>2M19182284-2816172</td><td>6759783812391009920</td><td>289.5952</td><td>-28.2715</td><td>9.756</td><td>-17.933</td><td>6.271</td><td>-0.595</td><td>4438</td><td>4329</td><td>7</td><td>2.1</td><td>2.21</td><td>0.02</td><td>-0.239</td><td>0.009</td><td>0.087</td><td>0.006</td><td>0.124</td><td>0.013</td><td>0</td><td>1.38</td><td>0.39</td><td>18.24</td><td>1.68</td><td>2.06</td><td>0.03</td><td>14.6</td><td>1.0</td><td>2.04</td><td>0.06</td><td>3.0</td><td>2.1</td><td>6.8</td><td>2.7</td><td>3.24</td><td>RGB</td></tr>\n",
       "<tr><td>212591385</td><td>2M13374700-1046588</td><td>3616757776317838464</td><td>204.4458</td><td>-10.783</td><td>320.985</td><td>50.457</td><td>6.843</td><td>2.143</td><td>4507</td><td>4404</td><td>13</td><td>2.32</td><td>2.43</td><td>0.03</td><td>-0.173</td><td>0.014</td><td>0.178</td><td>0.009</td><td>0.226</td><td>0.024</td><td>1</td><td>0.88</td><td>0.07</td><td>10.42</td><td>0.26</td><td>2.35</td><td>0.01</td><td>28.4</td><td>0.4</td><td>3.78</td><td>0.04</td><td>18.3</td><td>4.6</td><td>6.2</td><td>17.5</td><td>11.17</td><td>RGB</td></tr>\n",
       "<tr><td>210521826</td><td>2M04034090+1546195</td><td>45403134375970432</td><td>60.9204</td><td>15.7721</td><td>176.149</td><td>-26.646</td><td>9.781</td><td>-0.808</td><td>4634</td><td>4519</td><td>9</td><td>2.28</td><td>2.36</td><td>0.03</td><td>-0.361</td><td>0.009</td><td>0.097</td><td>0.007</td><td>0.114</td><td>0.018</td><td>0</td><td>1.05</td><td>0.14</td><td>12.44</td><td>0.52</td><td>2.27</td><td>0.01</td><td>23.3</td><td>0.5</td><td>3.16</td><td>0.06</td><td>7.5</td><td>2.9</td><td>4.7</td><td>6.4</td><td>5.51</td><td>RGB</td></tr>\n",
       "<tr><td>246067499</td><td>2M23464240-0751238</td><td>2436395519498043520</td><td>356.6767</td><td>-7.8566</td><td>81.44</td><td>-65.372</td><td>8.085</td><td>-0.616</td><td>4678</td><td>4613</td><td>10</td><td>2.95</td><td>3.06</td><td>0.02</td><td>0.171</td><td>0.009</td><td>0.018</td><td>0.006</td><td>0.034</td><td>0.018</td><td>0</td><td>1.11</td><td>0.08</td><td>5.3</td><td>0.13</td><td>3.03</td><td>0.0</td><td>135.1</td><td>0.7</td><td>11.67</td><td>0.14</td><td>9.3</td><td>2.3</td><td>3.0</td><td>9.2</td><td>41.76</td><td>RGB</td></tr>\n",
       "<tr><td>213894327</td><td>2M19194453-2757337</td><td>6759818520028101504</td><td>289.9356</td><td>-27.9594</td><td>10.177</td><td>-18.097</td><td>5.53</td><td>-0.854</td><td>4653</td><td>4542</td><td>14</td><td>2.57</td><td>2.62</td><td>0.04</td><td>-0.336</td><td>0.014</td><td>0.259</td><td>0.01</td><td>0.335</td><td>0.029</td><td>1</td><td>0.99</td><td>0.07</td><td>7.83</td><td>0.19</td><td>2.65</td><td>0.01</td><td>55.3</td><td>1.2</td><td>6.13</td><td>0.03</td><td>10.7</td><td>2.6</td><td>3.4</td><td>10.3</td><td>6.79</td><td>RGB</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>251621333</td><td>2M13252472-0046341</td><td>3686799243987416576</td><td>201.353</td><td>-0.7762</td><td>320.623</td><td>60.923</td><td>6.616</td><td>3.818</td><td>4821</td><td>4710</td><td>18</td><td>2.84</td><td>2.81</td><td>0.04</td><td>-0.634</td><td>0.015</td><td>0.328</td><td>0.014</td><td>0.458</td><td>0.043</td><td>1</td><td>0.93</td><td>0.05</td><td>6.42</td><td>0.11</td><td>2.79</td><td>0.0</td><td>75.8</td><td>0.4</td><td>8.0</td><td>0.07</td><td>11.5</td><td>2.1</td><td>2.6</td><td>11.5</td><td>1.21</td><td>RGB</td></tr>\n",
       "<tr><td>248918047</td><td>2M10340681+1349190</td><td>3885559537192733056</td><td>158.5284</td><td>13.8219</td><td>228.543</td><td>55.346</td><td>8.753</td><td>1.35</td><td>4718</td><td>4602</td><td>14</td><td>2.45</td><td>2.47</td><td>0.04</td><td>-0.52</td><td>0.013</td><td>0.132</td><td>0.011</td><td>0.287</td><td>0.032</td><td>-1</td><td>0.86</td><td>0.07</td><td>8.68</td><td>0.23</td><td>2.5</td><td>0.01</td><td>39.1</td><td>0.8</td><td>4.91</td><td>0.04</td><td>13.6</td><td>3.6</td><td>4.9</td><td>12.7</td><td>2.2</td><td>RGB</td></tr>\n",
       "<tr><td>211081828</td><td>2M03524636+2416452</td><td>66588524420451712</td><td>58.1932</td><td>24.2792</td><td>167.501</td><td>-22.508</td><td>9.002</td><td>-0.349</td><td>5004</td><td>4952</td><td>14</td><td>3.12</td><td>3.16</td><td>0.03</td><td>-0.249</td><td>0.009</td><td>0.042</td><td>0.008</td><td>0.033</td><td>0.033</td><td>0</td><td>1.36</td><td>0.13</td><td>5.09</td><td>0.16</td><td>3.16</td><td>0.0</td><td>173.9</td><td>0.9</td><td>13.74</td><td>0.21</td><td>3.1</td><td>0.9</td><td>1.3</td><td>3.2</td><td>3.25</td><td>RGB</td></tr>\n",
       "<tr><td>251586006</td><td>2M13252936-0137514</td><td>3638271714179963648</td><td>201.3723</td><td>-1.6309</td><td>320.197</td><td>60.094</td><td>6.983</td><td>2.743</td><td>4790</td><td>4688</td><td>14</td><td>2.82</td><td>2.84</td><td>0.04</td><td>-0.482</td><td>0.012</td><td>0.307</td><td>0.011</td><td>0.433</td><td>0.033</td><td>1</td><td>0.86</td><td>0.08</td><td>5.85</td><td>0.17</td><td>2.84</td><td>0.0</td><td>84.8</td><td>0.6</td><td>8.85</td><td>0.12</td><td>16.6</td><td>4.7</td><td>6.5</td><td>16.9</td><td>3.12</td><td>RGB</td></tr>\n",
       "<tr><td>213763794</td><td>2M19172557-2821003</td><td>6759691526436811008</td><td>289.3566</td><td>-28.3501</td><td>9.597</td><td>-17.767</td><td>5.546</td><td>-0.829</td><td>4710</td><td>4604</td><td>13</td><td>2.74</td><td>2.77</td><td>0.03</td><td>-0.381</td><td>0.012</td><td>0.239</td><td>0.01</td><td>0.301</td><td>0.028</td><td>1</td><td>0.99</td><td>0.06</td><td>7.31</td><td>0.15</td><td>2.71</td><td>0.01</td><td>63.3</td><td>1.1</td><td>6.82</td><td>0.04</td><td>10.0</td><td>2.1</td><td>2.7</td><td>9.6</td><td>5.63</td><td>RGB</td></tr>\n",
       "<tr><td>211844991</td><td>2M08255737+1756583</td><td>662156589790757504</td><td>126.4891</td><td>17.9495</td><td>206.361</td><td>28.678</td><td>11.095</td><td>1.789</td><td>4783</td><td>4682</td><td>14</td><td>2.61</td><td>2.64</td><td>0.04</td><td>-0.44</td><td>0.013</td><td>0.109</td><td>0.011</td><td>0.223</td><td>0.033</td><td>0</td><td>1.13</td><td>0.09</td><td>8.33</td><td>0.22</td><td>2.65</td><td>0.0</td><td>54.9</td><td>0.3</td><td>5.97</td><td>0.08</td><td>5.7</td><td>1.5</td><td>2.0</td><td>5.5</td><td>3.16</td><td>RGB</td></tr>\n",
       "<tr><td>211895016</td><td>2M08165721+1839104</td><td>657422745555024384</td><td>124.2384</td><td>18.6529</td><td>204.731</td><td>26.951</td><td>9.24</td><td>0.642</td><td>4653</td><td>4567</td><td>7</td><td>2.51</td><td>2.63</td><td>0.02</td><td>-0.054</td><td>0.007</td><td>0.042</td><td>0.005</td><td>0.056</td><td>0.014</td><td>0</td><td>1.16</td><td>0.07</td><td>9.32</td><td>0.18</td><td>2.56</td><td>0.01</td><td>45.7</td><td>0.6</td><td>5.11</td><td>0.03</td><td>6.7</td><td>1.3</td><td>1.6</td><td>6.8</td><td>11.99</td><td>RGB</td></tr>\n",
       "<tr><td>201681453</td><td>2M11570040+0319481</td><td>3893107894972402048</td><td>179.2517</td><td>3.33</td><td>271.921</td><td>62.877</td><td>8.136</td><td>1.739</td><td>4755</td><td>4649</td><td>42</td><td>2.61</td><td>2.7</td><td>0.1</td><td>-0.458</td><td>0.018</td><td>0.286</td><td>0.029</td><td>0.418</td><td>0.052</td><td>1</td><td>0.98</td><td>0.1</td><td>7.55</td><td>0.25</td><td>2.67</td><td>0.01</td><td>58.3</td><td>1.1</td><td>6.45</td><td>0.09</td><td>10.2</td><td>3.3</td><td>4.8</td><td>10.0</td><td>3.78</td><td>RGB</td></tr>\n",
       "<tr><td>220241308</td><td>2M01295659+0122422</td><td>2558473711414388352</td><td>22.4858</td><td>1.3784</td><td>142.479</td><td>-60.024</td><td>9.152</td><td>-2.147</td><td>4737</td><td>4625</td><td>10</td><td>2.62</td><td>2.65</td><td>0.03</td><td>-0.509</td><td>0.009</td><td>0.228</td><td>0.008</td><td>0.317</td><td>0.023</td><td>1</td><td>0.86</td><td>0.09</td><td>7.39</td><td>0.23</td><td>2.64</td><td>0.0</td><td>53.6</td><td>0.4</td><td>6.24</td><td>0.1</td><td>15.3</td><td>4.7</td><td>6.8</td><td>15.1</td><td>2.47</td><td>RGB</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=4661>\n",
       "   EPIC         APOGEE             GaiaEDR3      ... Age-mode  SFW  EvState\n",
       "                                                 ...   Gyr                 \n",
       "  int64         str18               int64        ... float64   str5   str3 \n",
       "--------- ------------------ ------------------- ... -------- ----- -------\n",
       "211821580 2M08270102+1737253  662088729307609216 ...     10.8  4.32     RGB\n",
       "212434736 2M13572534-1408010 6302108283398593152 ...      7.2  7.43     RGB\n",
       "212333123 2M13400342-1634554 3605202458865639552 ...     17.5  5.61     RGB\n",
       "212173678 2M08253330+2334276  678233202137154304 ...      4.1  6.53     RGB\n",
       "213789445 2M19182284-2816172 6759783812391009920 ...      2.7  3.24     RGB\n",
       "212591385 2M13374700-1046588 3616757776317838464 ...     17.5 11.17     RGB\n",
       "210521826 2M04034090+1546195   45403134375970432 ...      6.4  5.51     RGB\n",
       "246067499 2M23464240-0751238 2436395519498043520 ...      9.2 41.76     RGB\n",
       "213894327 2M19194453-2757337 6759818520028101504 ...     10.3  6.79     RGB\n",
       "      ...                ...                 ... ...      ...   ...     ...\n",
       "251621333 2M13252472-0046341 3686799243987416576 ...     11.5  1.21     RGB\n",
       "248918047 2M10340681+1349190 3885559537192733056 ...     12.7   2.2     RGB\n",
       "211081828 2M03524636+2416452   66588524420451712 ...      3.2  3.25     RGB\n",
       "251586006 2M13252936-0137514 3638271714179963648 ...     16.9  3.12     RGB\n",
       "213763794 2M19172557-2821003 6759691526436811008 ...      9.6  5.63     RGB\n",
       "211844991 2M08255737+1756583  662156589790757504 ...      5.5  3.16     RGB\n",
       "211895016 2M08165721+1839104  657422745555024384 ...      6.8 11.99     RGB\n",
       "201681453 2M11570040+0319481 3893107894972402048 ...     10.0  3.78     RGB\n",
       "220241308 2M01295659+0122422 2558473711414388352 ...     15.1  2.47     RGB"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age option 4 K2 data Warfield et al. 2024\n",
    "#Reading in the table, making sure all the tables have a column named Age in Gyr\n",
    "# and that every star in the table has an Age\n",
    "apok2raw = Table.read(\"Warfield2024.txt\", format=\"ascii.cds\")\n",
    "#this one has an age column in Gyr already so we're just going to rename it Age\n",
    "hasageapok2=np.where((apok2raw['Age']==apok2raw['Age']) & (apok2raw['Age']>0.1))\n",
    "apok2=apok2raw[hasageapok2]\n",
    "apok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135c6c2b-b3f4-48e8-b50b-a07883191546",
   "metadata": {},
   "outputs": [],
   "source": [
    "agedata= apokasc2\n",
    "agedata2= apok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f927d0ef-3328-443f-9d1d-683402672d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993 4451\n"
     ]
    }
   ],
   "source": [
    "#Option 1 TESS Theodoridis et al. 2025\n",
    "# intersect2, ind_a2, ind_b2 = np.intersect1d(data_masked['tic_v8_id'],agedata2['TIC'], return_indices=True)\n",
    "\n",
    "#Option 2 APOKASC-2 Pinsonneault et al. 2018\n",
    "intersect, ind_a, ind_b = np.intersect1d(data_masked['sdss4_apogee_id'],agedata['2MASS'], return_indices=True) \n",
    "\n",
    "#Option 3 APOKASC-3 Pinsonneault et al. 2025\n",
    "#intersect, ind_a, ind_b = np.intersect1d(data_masked['gaia_dr3_source_id'],agedata['GaiaDR3'], return_indices=True) \n",
    "\n",
    "#Option 4 APO-K2 Warfield et al. 2024\n",
    "intersect2, ind_a2, ind_b2 = np.intersect1d(data_masked['sdss4_apogee_id'],agedata2['APOGEE'], return_indices=True) \n",
    "\n",
    "print(len(ind_b), len(ind_b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be3eb51-5d32-448b-a392-89487b460ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21a705e5-d564-47dd-84ec-e4192228caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d1412-8db3-45b1-b697-20eec53a4b6c",
   "metadata": {},
   "source": [
    "## First Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67d4f1a-b90f-4121-a81b-afd299661f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullx = np.dstack([data_masked['teff'][ind_a],data_masked['logg'][ind_a], data_masked['m_h_atm'][ind_a],\n",
    "                   data_masked['alpha_m_atm'][ind_a], data_masked['c_h'][ind_a], data_masked['n_h'][ind_a]])[0]\n",
    "\n",
    "fully = np.dstack([agedata['Age'][ind_b]])[0] #for Pinsonneault 2018\n",
    "\n",
    "#remove non-finite entries!\n",
    "mask = np.all(np.isfinite(fullx), axis=1) & np.all(np.isfinite(fully), axis=1)\n",
    "fullx, fully = fullx[mask], fully[mask]\n",
    "\n",
    "scaling_x = np.median(fullx, axis=0)\n",
    "scaling_y = np.median(fully, axis=0)\n",
    "\n",
    "fullx, fully = fullx/scaling_x, fully/scaling_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16572b8-0b68-48aa-8154-52134dea03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_per_layer=20\n",
    "layers=5\n",
    "iterations=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a8d619-e578-425a-aa24-feb2e5b705a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"test\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"test\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m140\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,841</span> (7.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,841\u001b[0m (7.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,841</span> (7.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,841\u001b[0m (7.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#start with an input layer\n",
    "inputs = keras.Input(shape=(6,))\n",
    "#now we add the Dense layers (indicating the previous layer in the brackets following the layer declaration\n",
    "\n",
    "#change this part if you're changing the number of layers\n",
    "layer1 =keras.layers.Dense(neurons_per_layer, activation='relu')(inputs)\n",
    "layer2 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer1)\n",
    "layer3 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer2)\n",
    "layer4 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer3)\n",
    "layer5 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer4)\n",
    "\n",
    "#then the output layer YOU ALSO HAVE TO MAKE THIS MATCH YOUR NUMBER OF LAYERS\n",
    "outputs = keras.layers.Dense(1)(layer5)\n",
    "\n",
    "\n",
    "# then we put that all together in the Model object\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='test')\n",
    "#and we can print a summary to check it all went to plan\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49f6c53-d915-4af4-9a1b-9fe2151140ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dbbfa16-1d2c-4204-9cbd-592fcb53d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenpercent=len(agedata['Age'][ind_b])//10 #figure out what ten percent of this set of age data is\n",
    "\n",
    "#last name before M \n",
    "#trainbin=slice(0,-1*tenpercent-1)\n",
    "#testing=slice(-1*tenpercent,-1)\n",
    "\n",
    "\n",
    "#last name M or later\n",
    "trainbin=slice(tenpercent+1,-1)\n",
    "testing=slice(0,tenpercent)\n",
    "\n",
    "\n",
    "x_train, y_train = fullx[trainbin], fully[trainbin]\n",
    "x_test, y_test = fullx[testing], fully[testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed78eb61-fae5-4e7c-a84b-5a149a9e2486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 1.5923 - val_accuracy: 0.0000e+00 - val_loss: 0.7158\n",
      "Epoch 2/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 2.0354e-04 - loss: 0.7432 - val_accuracy: 0.0039 - val_loss: 0.5393\n",
      "Epoch 3/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 8.1417e-04 - loss: 0.5893 - val_accuracy: 0.0039 - val_loss: 0.5189\n",
      "Epoch 4/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.5137 - val_accuracy: 0.0039 - val_loss: 0.4270\n",
      "Epoch 5/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.4536 - val_accuracy: 0.0039 - val_loss: 0.3761\n",
      "Epoch 6/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.4065 - val_accuracy: 0.0039 - val_loss: 0.3381\n",
      "Epoch 7/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.3808 - val_accuracy: 0.0039 - val_loss: 0.3140\n",
      "Epoch 8/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.3631 - val_accuracy: 0.0039 - val_loss: 0.3047\n",
      "Epoch 9/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.3484 - val_accuracy: 0.0039 - val_loss: 0.2889\n",
      "Epoch 10/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.3296 - val_accuracy: 0.0039 - val_loss: 0.2764\n",
      "Epoch 11/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.3084 - val_accuracy: 0.0039 - val_loss: 0.2584\n",
      "Epoch 12/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2933 - val_accuracy: 0.0039 - val_loss: 0.2371\n",
      "Epoch 13/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2757 - val_accuracy: 0.0039 - val_loss: 0.2252\n",
      "Epoch 14/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2626 - val_accuracy: 0.0039 - val_loss: 0.2239\n",
      "Epoch 15/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2506 - val_accuracy: 0.0039 - val_loss: 0.2219\n",
      "Epoch 16/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.2470 - val_accuracy: 0.0039 - val_loss: 0.2115\n",
      "Epoch 17/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2436 - val_accuracy: 0.0039 - val_loss: 0.2112\n",
      "Epoch 18/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.2452 - val_accuracy: 0.0039 - val_loss: 0.2096\n",
      "Epoch 19/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2373 - val_accuracy: 0.0039 - val_loss: 0.2082\n",
      "Epoch 20/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2367 - val_accuracy: 0.0039 - val_loss: 0.2085\n",
      "Epoch 21/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2355 - val_accuracy: 0.0039 - val_loss: 0.2107\n",
      "Epoch 22/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2347 - val_accuracy: 0.0039 - val_loss: 0.2047\n",
      "Epoch 23/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2335 - val_accuracy: 0.0039 - val_loss: 0.2128\n",
      "Epoch 24/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2347 - val_accuracy: 0.0039 - val_loss: 0.2045\n",
      "Epoch 25/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2321 - val_accuracy: 0.0039 - val_loss: 0.2164\n",
      "Epoch 26/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2332 - val_accuracy: 0.0039 - val_loss: 0.2045\n",
      "Epoch 27/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2282 - val_accuracy: 0.0039 - val_loss: 0.2025\n",
      "Epoch 28/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2310 - val_accuracy: 0.0039 - val_loss: 0.2019\n",
      "Epoch 29/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2274 - val_accuracy: 0.0039 - val_loss: 0.2074\n",
      "Epoch 30/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.2254 - val_accuracy: 0.0039 - val_loss: 0.2017\n",
      "Epoch 31/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2236 - val_accuracy: 0.0039 - val_loss: 0.2047\n",
      "Epoch 32/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2236 - val_accuracy: 0.0039 - val_loss: 0.2125\n",
      "Epoch 33/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.2224 - val_accuracy: 0.0039 - val_loss: 0.2036\n",
      "Epoch 34/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2201 - val_accuracy: 0.0039 - val_loss: 0.1999\n",
      "Epoch 35/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2191 - val_accuracy: 0.0039 - val_loss: 0.2041\n",
      "Epoch 36/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2190 - val_accuracy: 0.0039 - val_loss: 0.2033\n",
      "Epoch 37/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.2182 - val_accuracy: 0.0039 - val_loss: 0.1993\n",
      "Epoch 38/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.2180 - val_accuracy: 0.0039 - val_loss: 0.2035\n",
      "Epoch 39/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.2185 - val_accuracy: 0.0039 - val_loss: 0.2002\n",
      "Epoch 40/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0012 - loss: 0.2183 - val_accuracy: 0.0039 - val_loss: 0.2009\n",
      "Epoch 41/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.2165 - val_accuracy: 0.0039 - val_loss: 0.1981\n",
      "Epoch 42/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2156 - val_accuracy: 0.0039 - val_loss: 0.1996\n",
      "Epoch 43/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2141 - val_accuracy: 0.0039 - val_loss: 0.1964\n",
      "Epoch 44/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2139 - val_accuracy: 0.0039 - val_loss: 0.2110\n",
      "Epoch 45/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2168 - val_accuracy: 0.0039 - val_loss: 0.1970\n",
      "Epoch 46/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.2150 - val_accuracy: 0.0039 - val_loss: 0.2002\n",
      "Epoch 47/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2127 - val_accuracy: 0.0039 - val_loss: 0.2003\n",
      "Epoch 48/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2131 - val_accuracy: 0.0039 - val_loss: 0.1959\n",
      "Epoch 49/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2122 - val_accuracy: 0.0039 - val_loss: 0.1977\n",
      "Epoch 50/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.2113 - val_accuracy: 0.0039 - val_loss: 0.2029\n",
      "Epoch 51/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2117 - val_accuracy: 0.0039 - val_loss: 0.1961\n",
      "Epoch 52/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2116 - val_accuracy: 0.0039 - val_loss: 0.1970\n",
      "Epoch 53/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2104 - val_accuracy: 0.0039 - val_loss: 0.1956\n",
      "Epoch 54/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2107 - val_accuracy: 0.0039 - val_loss: 0.1970\n",
      "Epoch 55/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2088 - val_accuracy: 0.0039 - val_loss: 0.1960\n",
      "Epoch 56/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2099 - val_accuracy: 0.0039 - val_loss: 0.1943\n",
      "Epoch 57/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2125 - val_accuracy: 0.0039 - val_loss: 0.1974\n",
      "Epoch 58/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2083 - val_accuracy: 0.0039 - val_loss: 0.1947\n",
      "Epoch 59/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2070 - val_accuracy: 0.0039 - val_loss: 0.1957\n",
      "Epoch 60/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.2056 - val_accuracy: 0.0039 - val_loss: 0.1958\n",
      "Epoch 61/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2077 - val_accuracy: 0.0039 - val_loss: 0.1915\n",
      "Epoch 62/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2067 - val_accuracy: 0.0039 - val_loss: 0.2041\n",
      "Epoch 63/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.2065 - val_accuracy: 0.0039 - val_loss: 0.1973\n",
      "Epoch 64/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2071 - val_accuracy: 0.0039 - val_loss: 0.1904\n",
      "Epoch 65/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2066 - val_accuracy: 0.0039 - val_loss: 0.1901\n",
      "Epoch 66/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.2096 - val_accuracy: 0.0039 - val_loss: 0.1989\n",
      "Epoch 67/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2099 - val_accuracy: 0.0039 - val_loss: 0.1910\n",
      "Epoch 68/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.2068 - val_accuracy: 0.0039 - val_loss: 0.1995\n",
      "Epoch 69/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2057 - val_accuracy: 0.0039 - val_loss: 0.1900\n",
      "Epoch 70/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.2049 - val_accuracy: 0.0039 - val_loss: 0.1934\n",
      "Epoch 71/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0012 - loss: 0.2052 - val_accuracy: 0.0039 - val_loss: 0.1878\n",
      "Epoch 72/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2101 - val_accuracy: 0.0039 - val_loss: 0.1911\n",
      "Epoch 73/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.2047 - val_accuracy: 0.0039 - val_loss: 0.1926\n",
      "Epoch 74/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2041 - val_accuracy: 0.0039 - val_loss: 0.1917\n",
      "Epoch 75/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.2027 - val_accuracy: 0.0039 - val_loss: 0.1883\n",
      "Epoch 76/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.2034 - val_accuracy: 0.0039 - val_loss: 0.1888\n",
      "Epoch 77/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.2022 - val_accuracy: 0.0039 - val_loss: 0.2033\n",
      "Epoch 78/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2039 - val_accuracy: 0.0039 - val_loss: 0.1992\n",
      "Epoch 79/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2042 - val_accuracy: 0.0039 - val_loss: 0.1871\n",
      "Epoch 80/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2046 - val_accuracy: 0.0039 - val_loss: 0.1903\n",
      "Epoch 81/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.2003 - val_accuracy: 0.0039 - val_loss: 0.2000\n",
      "Epoch 82/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2018 - val_accuracy: 0.0039 - val_loss: 0.1919\n",
      "Epoch 83/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2001 - val_accuracy: 0.0039 - val_loss: 0.1897\n",
      "Epoch 84/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2010 - val_accuracy: 0.0039 - val_loss: 0.1891\n",
      "Epoch 85/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2007 - val_accuracy: 0.0039 - val_loss: 0.1877\n",
      "Epoch 86/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1987 - val_accuracy: 0.0039 - val_loss: 0.1865\n",
      "Epoch 87/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1995 - val_accuracy: 0.0039 - val_loss: 0.1899\n",
      "Epoch 88/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1981 - val_accuracy: 0.0039 - val_loss: 0.1883\n",
      "Epoch 89/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1992 - val_accuracy: 0.0039 - val_loss: 0.1868\n",
      "Epoch 90/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.2033 - val_accuracy: 0.0039 - val_loss: 0.1877\n",
      "Epoch 91/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1984 - val_accuracy: 0.0039 - val_loss: 0.1862\n",
      "Epoch 92/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1980 - val_accuracy: 0.0039 - val_loss: 0.1857\n",
      "Epoch 93/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.2009 - val_accuracy: 0.0039 - val_loss: 0.1862\n",
      "Epoch 94/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1987 - val_accuracy: 0.0039 - val_loss: 0.1879\n",
      "Epoch 95/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1977 - val_accuracy: 0.0039 - val_loss: 0.1873\n",
      "Epoch 96/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1978 - val_accuracy: 0.0039 - val_loss: 0.1850\n",
      "Epoch 97/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1986 - val_accuracy: 0.0039 - val_loss: 0.1859\n",
      "Epoch 98/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.2013 - val_accuracy: 0.0039 - val_loss: 0.1940\n",
      "Epoch 99/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1993 - val_accuracy: 0.0039 - val_loss: 0.1843\n",
      "Epoch 100/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1982 - val_accuracy: 0.0039 - val_loss: 0.1950\n",
      "Epoch 101/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1956 - val_accuracy: 0.0039 - val_loss: 0.1847\n",
      "Epoch 102/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1971 - val_accuracy: 0.0039 - val_loss: 0.1916\n",
      "Epoch 103/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1955 - val_accuracy: 0.0039 - val_loss: 0.1852\n",
      "Epoch 104/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1968 - val_accuracy: 0.0039 - val_loss: 0.1941\n",
      "Epoch 105/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.2011 - val_accuracy: 0.0039 - val_loss: 0.1817\n",
      "Epoch 106/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.2007 - val_accuracy: 0.0039 - val_loss: 0.1849\n",
      "Epoch 107/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1955 - val_accuracy: 0.0039 - val_loss: 0.1827\n",
      "Epoch 108/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1955 - val_accuracy: 0.0039 - val_loss: 0.1806\n",
      "Epoch 109/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1959 - val_accuracy: 0.0039 - val_loss: 0.1915\n",
      "Epoch 110/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1947 - val_accuracy: 0.0039 - val_loss: 0.1863\n",
      "Epoch 111/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1931 - val_accuracy: 0.0039 - val_loss: 0.1797\n",
      "Epoch 112/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1963 - val_accuracy: 0.0039 - val_loss: 0.1896\n",
      "Epoch 113/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1949 - val_accuracy: 0.0039 - val_loss: 0.1876\n",
      "Epoch 114/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1945 - val_accuracy: 0.0039 - val_loss: 0.1858\n",
      "Epoch 115/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1932 - val_accuracy: 0.0039 - val_loss: 0.1843\n",
      "Epoch 116/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1942 - val_accuracy: 0.0039 - val_loss: 0.1831\n",
      "Epoch 117/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1931 - val_accuracy: 0.0039 - val_loss: 0.1820\n",
      "Epoch 118/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1926 - val_accuracy: 0.0039 - val_loss: 0.1798\n",
      "Epoch 119/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1935 - val_accuracy: 0.0039 - val_loss: 0.1832\n",
      "Epoch 120/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1924 - val_accuracy: 0.0039 - val_loss: 0.1819\n",
      "Epoch 121/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1939 - val_accuracy: 0.0039 - val_loss: 0.1812\n",
      "Epoch 122/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1957 - val_accuracy: 0.0039 - val_loss: 0.1881\n",
      "Epoch 123/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1956 - val_accuracy: 0.0039 - val_loss: 0.1809\n",
      "Epoch 124/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1919 - val_accuracy: 0.0039 - val_loss: 0.1800\n",
      "Epoch 125/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1926 - val_accuracy: 0.0039 - val_loss: 0.1853\n",
      "Epoch 126/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1970 - val_accuracy: 0.0039 - val_loss: 0.1961\n",
      "Epoch 127/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1928 - val_accuracy: 0.0039 - val_loss: 0.1799\n",
      "Epoch 128/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1937 - val_accuracy: 0.0039 - val_loss: 0.1871\n",
      "Epoch 129/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1949 - val_accuracy: 0.0039 - val_loss: 0.1812\n",
      "Epoch 130/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1915 - val_accuracy: 0.0039 - val_loss: 0.1827\n",
      "Epoch 131/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0010 - loss: 0.1925 - val_accuracy: 0.0039 - val_loss: 0.1812\n",
      "Epoch 132/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1905 - val_accuracy: 0.0039 - val_loss: 0.1849\n",
      "Epoch 133/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1901 - val_accuracy: 0.0039 - val_loss: 0.1786\n",
      "Epoch 134/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1910 - val_accuracy: 0.0039 - val_loss: 0.1836\n",
      "Epoch 135/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1910 - val_accuracy: 0.0039 - val_loss: 0.1815\n",
      "Epoch 136/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1902 - val_accuracy: 0.0039 - val_loss: 0.1817\n",
      "Epoch 137/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1904 - val_accuracy: 0.0039 - val_loss: 0.1855\n",
      "Epoch 138/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1905 - val_accuracy: 0.0039 - val_loss: 0.1846\n",
      "Epoch 139/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1913 - val_accuracy: 0.0039 - val_loss: 0.1772\n",
      "Epoch 140/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1895 - val_accuracy: 0.0039 - val_loss: 0.1800\n",
      "Epoch 141/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1927 - val_accuracy: 0.0039 - val_loss: 0.1992\n",
      "Epoch 142/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1918 - val_accuracy: 0.0039 - val_loss: 0.1758\n",
      "Epoch 143/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1904 - val_accuracy: 0.0039 - val_loss: 0.1795\n",
      "Epoch 144/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1933 - val_accuracy: 0.0039 - val_loss: 0.1878\n",
      "Epoch 145/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0010 - loss: 0.1958 - val_accuracy: 0.0039 - val_loss: 0.1871\n",
      "Epoch 146/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1898 - val_accuracy: 0.0039 - val_loss: 0.1781\n",
      "Epoch 147/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1891 - val_accuracy: 0.0039 - val_loss: 0.1903\n",
      "Epoch 148/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1883 - val_accuracy: 0.0039 - val_loss: 0.1793\n",
      "Epoch 149/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0010 - loss: 0.1877 - val_accuracy: 0.0039 - val_loss: 0.1966\n",
      "Epoch 150/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1898 - val_accuracy: 0.0039 - val_loss: 0.1754\n",
      "Epoch 151/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1927 - val_accuracy: 0.0039 - val_loss: 0.1916\n",
      "Epoch 152/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0010 - loss: 0.1874 - val_accuracy: 0.0039 - val_loss: 0.1785\n",
      "Epoch 153/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1871 - val_accuracy: 0.0039 - val_loss: 0.1905\n",
      "Epoch 154/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1889 - val_accuracy: 0.0039 - val_loss: 0.1763\n",
      "Epoch 155/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1885 - val_accuracy: 0.0039 - val_loss: 0.1845\n",
      "Epoch 156/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1870 - val_accuracy: 0.0039 - val_loss: 0.1768\n",
      "Epoch 157/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1869 - val_accuracy: 0.0039 - val_loss: 0.1861\n",
      "Epoch 158/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1862 - val_accuracy: 0.0039 - val_loss: 0.1792\n",
      "Epoch 159/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1864 - val_accuracy: 0.0039 - val_loss: 0.1868\n",
      "Epoch 160/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1858 - val_accuracy: 0.0039 - val_loss: 0.1845\n",
      "Epoch 161/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.1909 - val_accuracy: 0.0039 - val_loss: 0.1847\n",
      "Epoch 162/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1850 - val_accuracy: 0.0039 - val_loss: 0.1828\n",
      "Epoch 163/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1879 - val_accuracy: 0.0039 - val_loss: 0.1804\n",
      "Epoch 164/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1845 - val_accuracy: 0.0039 - val_loss: 0.1876\n",
      "Epoch 165/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1886 - val_accuracy: 0.0039 - val_loss: 0.1766\n",
      "Epoch 166/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0010 - loss: 0.1899 - val_accuracy: 0.0039 - val_loss: 0.1882\n",
      "Epoch 167/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0012 - loss: 0.1876 - val_accuracy: 0.0039 - val_loss: 0.1768\n",
      "Epoch 168/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0010 - loss: 0.1842 - val_accuracy: 0.0039 - val_loss: 0.1813\n",
      "Epoch 169/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 8.1417e-04 - loss: 0.1847 - val_accuracy: 0.0039 - val_loss: 0.1784\n",
      "Epoch 170/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0010 - loss: 0.1850 - val_accuracy: 0.0039 - val_loss: 0.1881\n",
      "Epoch 171/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 8.1417e-04 - loss: 0.1867 - val_accuracy: 0.0039 - val_loss: 0.1819\n",
      "Epoch 172/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1848 - val_accuracy: 0.0039 - val_loss: 0.1817\n",
      "Epoch 173/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1845 - val_accuracy: 0.0039 - val_loss: 0.1792\n",
      "Epoch 174/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1828 - val_accuracy: 0.0039 - val_loss: 0.1827\n",
      "Epoch 175/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.1839 - val_accuracy: 0.0039 - val_loss: 0.1814\n",
      "Epoch 176/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1824 - val_accuracy: 0.0039 - val_loss: 0.1810\n",
      "Epoch 177/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1848 - val_accuracy: 0.0039 - val_loss: 0.1824\n",
      "Epoch 178/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1853 - val_accuracy: 0.0039 - val_loss: 0.1819\n",
      "Epoch 179/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1831 - val_accuracy: 0.0039 - val_loss: 0.1839\n",
      "Epoch 180/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1832 - val_accuracy: 0.0039 - val_loss: 0.1833\n",
      "Epoch 181/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1830 - val_accuracy: 0.0039 - val_loss: 0.1801\n",
      "Epoch 182/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1826 - val_accuracy: 0.0039 - val_loss: 0.1877\n",
      "Epoch 183/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1841 - val_accuracy: 0.0039 - val_loss: 0.1836\n",
      "Epoch 184/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1832 - val_accuracy: 0.0039 - val_loss: 0.1940\n",
      "Epoch 185/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1852 - val_accuracy: 0.0039 - val_loss: 0.1818\n",
      "Epoch 186/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1853 - val_accuracy: 0.0039 - val_loss: 0.1827\n",
      "Epoch 187/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1843 - val_accuracy: 0.0039 - val_loss: 0.1776\n",
      "Epoch 188/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 8.1417e-04 - loss: 0.1838 - val_accuracy: 0.0039 - val_loss: 0.1895\n",
      "Epoch 189/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1823 - val_accuracy: 0.0039 - val_loss: 0.1788\n",
      "Epoch 190/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1816 - val_accuracy: 0.0039 - val_loss: 0.1910\n",
      "Epoch 191/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1820 - val_accuracy: 0.0039 - val_loss: 0.1805\n",
      "Epoch 192/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0012 - loss: 0.1811 - val_accuracy: 0.0039 - val_loss: 0.1839\n",
      "Epoch 193/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0012 - loss: 0.1818 - val_accuracy: 0.0039 - val_loss: 0.1814\n",
      "Epoch 194/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0010 - loss: 0.1848 - val_accuracy: 0.0039 - val_loss: 0.1777\n",
      "Epoch 195/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1883 - val_accuracy: 0.0039 - val_loss: 0.1861\n",
      "Epoch 196/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0010 - loss: 0.1827 - val_accuracy: 0.0039 - val_loss: 0.1784\n",
      "Epoch 197/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0012 - loss: 0.1803 - val_accuracy: 0.0039 - val_loss: 0.1796\n",
      "Epoch 198/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0012 - loss: 0.1809 - val_accuracy: 0.0039 - val_loss: 0.1943\n",
      "Epoch 199/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0010 - loss: 0.1826 - val_accuracy: 0.0039 - val_loss: 0.1776\n",
      "Epoch 200/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0012 - loss: 0.1799 - val_accuracy: 0.0039 - val_loss: 0.1856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24f09ca1490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=iterations, validation_split=0.05, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9945274-b190-45b2-954c-5e681f461a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "599\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "718d7396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With  20 neurons per layer,  5 layers, and  200 iterations\n",
      "using the training set slice(600, -1, None)\n",
      "65.6093489148581 percent of the ages are good\n",
      "34.390651085141904 percent of the ages are bad\n"
     ]
    }
   ],
   "source": [
    "metric=0.3 #is the accuracy better than 30%?\n",
    "goodfit=np.where(((1-metric) < predictions/y_test) & ((1+metric) > predictions/y_test)) \n",
    "badfit=np.where(((1-metric) > predictions/y_test) | ((1+metric) < predictions/y_test))\n",
    "\n",
    "print ('With ', neurons_per_layer, 'neurons per layer, ', layers, 'layers, and ', iterations, 'iterations')\n",
    "print ('using the training set', trainbin)\n",
    "print (len(goodfit[0])/len(y_test)*100, 'percent of the ages are good')\n",
    "print (len(badfit[0])/len(y_test)*100, 'percent of the ages are bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6133233a-176f-49b3-8768-75f30fc38369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425631\n",
      "\u001b[1m13301/13301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "DR19x = np.dstack([data_masked['teff'],data_masked['logg'], data_masked['m_h_atm'],\n",
    "                   data_masked['alpha_m_atm'], data_masked['c_h'], data_masked['n_h']])[0]\n",
    "print(len(data_masked['teff']))\n",
    "\n",
    "DR19x= DR19x/scaling_x\n",
    "predictionsDR19 = model.predict(DR19x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799fc4d-9d03-422d-8658-825852967a4a",
   "metadata": {},
   "source": [
    "## Training Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82c3b69f-6967-45dd-ba85-0a09732fb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullx2 = np.dstack([data_masked['teff'][ind_a2],data_masked['logg'][ind_a2], data_masked['m_h_atm'][ind_a2],\n",
    "                   data_masked['alpha_m_atm'][ind_a2], data_masked['c_h'][ind_a2], data_masked['n_h'][ind_a2]])[0]\n",
    "\n",
    "fully2 = np.dstack([agedata2['Age'][ind_b2]])[0] #for Pinsonneault 2018\n",
    "\n",
    "#remove non-finite entries!\n",
    "mask2 = np.all(np.isfinite(fullx2), axis=1) & np.all(np.isfinite(fully2), axis=1)\n",
    "fullx2, fully2 = fullx2[mask2], fully2[mask2]\n",
    "\n",
    "scaling_x2 = np.median(fullx2, axis=0)\n",
    "scaling_y2 = np.median(fully2, axis=0)\n",
    "fullx2, fully2 = fullx2/scaling_x2, fully2/scaling_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15087510-3a8e-48a9-87c4-8d82826cfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenpercent2=len(agedata2['Age'][ind_b2])//10 #figure out what ten percent of this set of age data is\n",
    "\n",
    "#last name before M \n",
    "#trainbin=slice(0,-1*tenpercent-1)\n",
    "#testing=slice(-1*tenpercent,-1)\n",
    "\n",
    "\n",
    "#last name M or later\n",
    "trainbin2=slice(tenpercent2+1,-1)\n",
    "testing2=slice(0,tenpercent2)\n",
    "\n",
    "\n",
    "x_train2, y_train2 = fullx2[trainbin2], fully2[trainbin2]\n",
    "x_test2, y_test2 = fullx2[testing2], fully2[testing2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae47b020-77bc-4dc3-ad7c-9ff72cd1231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0086 - loss: 0.9004 - val_accuracy: 0.0102 - val_loss: 0.6126\n",
      "Epoch 2/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.6228 - val_accuracy: 0.0102 - val_loss: 0.5414\n",
      "Epoch 3/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5864 - val_accuracy: 0.0102 - val_loss: 0.5437\n",
      "Epoch 4/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5804 - val_accuracy: 0.0102 - val_loss: 0.5389\n",
      "Epoch 5/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5775 - val_accuracy: 0.0102 - val_loss: 0.5375\n",
      "Epoch 6/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0094 - loss: 0.5718 - val_accuracy: 0.0102 - val_loss: 0.5373\n",
      "Epoch 7/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0094 - loss: 0.5685 - val_accuracy: 0.0102 - val_loss: 0.5358\n",
      "Epoch 8/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0094 - loss: 0.5646 - val_accuracy: 0.0102 - val_loss: 0.5342\n",
      "Epoch 9/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0094 - loss: 0.5642 - val_accuracy: 0.0102 - val_loss: 0.5313\n",
      "Epoch 10/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5611 - val_accuracy: 0.0102 - val_loss: 0.5297\n",
      "Epoch 11/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5588 - val_accuracy: 0.0102 - val_loss: 0.5325\n",
      "Epoch 12/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5591 - val_accuracy: 0.0102 - val_loss: 0.5261\n",
      "Epoch 13/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5558 - val_accuracy: 0.0102 - val_loss: 0.5270\n",
      "Epoch 14/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0094 - loss: 0.5527 - val_accuracy: 0.0102 - val_loss: 0.5293\n",
      "Epoch 15/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0094 - loss: 0.5514 - val_accuracy: 0.0102 - val_loss: 0.5283\n",
      "Epoch 16/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5488 - val_accuracy: 0.0102 - val_loss: 0.5259\n",
      "Epoch 17/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5464 - val_accuracy: 0.0102 - val_loss: 0.5271\n",
      "Epoch 18/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0094 - loss: 0.5472 - val_accuracy: 0.0102 - val_loss: 0.5265\n",
      "Epoch 19/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5448 - val_accuracy: 0.0102 - val_loss: 0.5331\n",
      "Epoch 20/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5444 - val_accuracy: 0.0102 - val_loss: 0.5346\n",
      "Epoch 21/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5423 - val_accuracy: 0.0102 - val_loss: 0.5277\n",
      "Epoch 22/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5410 - val_accuracy: 0.0102 - val_loss: 0.5299\n",
      "Epoch 23/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0094 - loss: 0.5379 - val_accuracy: 0.0102 - val_loss: 0.5347\n",
      "Epoch 24/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0094 - loss: 0.5371 - val_accuracy: 0.0102 - val_loss: 0.5376\n",
      "Epoch 25/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0094 - loss: 0.5363 - val_accuracy: 0.0102 - val_loss: 0.5424\n",
      "Epoch 26/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5362 - val_accuracy: 0.0102 - val_loss: 0.5403\n",
      "Epoch 27/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0094 - loss: 0.5388 - val_accuracy: 0.0102 - val_loss: 0.5374\n",
      "Epoch 28/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5307 - val_accuracy: 0.0102 - val_loss: 0.5354\n",
      "Epoch 29/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5280 - val_accuracy: 0.0102 - val_loss: 0.5304\n",
      "Epoch 30/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5282 - val_accuracy: 0.0102 - val_loss: 0.5392\n",
      "Epoch 31/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5249 - val_accuracy: 0.0102 - val_loss: 0.5388\n",
      "Epoch 32/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5270 - val_accuracy: 0.0102 - val_loss: 0.5375\n",
      "Epoch 33/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5268 - val_accuracy: 0.0102 - val_loss: 0.5440\n",
      "Epoch 34/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5245 - val_accuracy: 0.0102 - val_loss: 0.5312\n",
      "Epoch 35/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5218 - val_accuracy: 0.0102 - val_loss: 0.5336\n",
      "Epoch 36/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5220 - val_accuracy: 0.0102 - val_loss: 0.5490\n",
      "Epoch 37/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.5213 - val_accuracy: 0.0102 - val_loss: 0.5368\n",
      "Epoch 38/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5193 - val_accuracy: 0.0102 - val_loss: 0.5498\n",
      "Epoch 39/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5248 - val_accuracy: 0.0102 - val_loss: 0.5475\n",
      "Epoch 40/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5223 - val_accuracy: 0.0102 - val_loss: 0.5434\n",
      "Epoch 41/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5194 - val_accuracy: 0.0102 - val_loss: 0.5529\n",
      "Epoch 42/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0094 - loss: 0.5246 - val_accuracy: 0.0102 - val_loss: 0.5365\n",
      "Epoch 43/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5170 - val_accuracy: 0.0102 - val_loss: 0.5340\n",
      "Epoch 44/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5171 - val_accuracy: 0.0102 - val_loss: 0.5394\n",
      "Epoch 45/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5176 - val_accuracy: 0.0102 - val_loss: 0.5349\n",
      "Epoch 46/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5146 - val_accuracy: 0.0102 - val_loss: 0.5358\n",
      "Epoch 47/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5170 - val_accuracy: 0.0102 - val_loss: 0.5411\n",
      "Epoch 48/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5192 - val_accuracy: 0.0102 - val_loss: 0.5369\n",
      "Epoch 49/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5193 - val_accuracy: 0.0102 - val_loss: 0.5350\n",
      "Epoch 50/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5206 - val_accuracy: 0.0102 - val_loss: 0.5364\n",
      "Epoch 51/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5162 - val_accuracy: 0.0102 - val_loss: 0.5331\n",
      "Epoch 52/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5164 - val_accuracy: 0.0102 - val_loss: 0.5381\n",
      "Epoch 53/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5119 - val_accuracy: 0.0102 - val_loss: 0.5343\n",
      "Epoch 54/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5120 - val_accuracy: 0.0102 - val_loss: 0.5365\n",
      "Epoch 55/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5121 - val_accuracy: 0.0102 - val_loss: 0.5401\n",
      "Epoch 56/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5123 - val_accuracy: 0.0102 - val_loss: 0.5463\n",
      "Epoch 57/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5117 - val_accuracy: 0.0102 - val_loss: 0.5497\n",
      "Epoch 58/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0094 - loss: 0.5171 - val_accuracy: 0.0102 - val_loss: 0.5502\n",
      "Epoch 59/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5114 - val_accuracy: 0.0102 - val_loss: 0.5506\n",
      "Epoch 60/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5148 - val_accuracy: 0.0102 - val_loss: 0.5411\n",
      "Epoch 61/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5115 - val_accuracy: 0.0102 - val_loss: 0.5356\n",
      "Epoch 62/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5137 - val_accuracy: 0.0102 - val_loss: 0.5356\n",
      "Epoch 63/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5119 - val_accuracy: 0.0102 - val_loss: 0.5481\n",
      "Epoch 64/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5117 - val_accuracy: 0.0102 - val_loss: 0.5412\n",
      "Epoch 65/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5107 - val_accuracy: 0.0102 - val_loss: 0.5321\n",
      "Epoch 66/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5128 - val_accuracy: 0.0102 - val_loss: 0.5368\n",
      "Epoch 67/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5126 - val_accuracy: 0.0102 - val_loss: 0.5350\n",
      "Epoch 68/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5076 - val_accuracy: 0.0102 - val_loss: 0.5344\n",
      "Epoch 69/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5079 - val_accuracy: 0.0102 - val_loss: 0.5370\n",
      "Epoch 70/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5119 - val_accuracy: 0.0102 - val_loss: 0.5383\n",
      "Epoch 71/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5087 - val_accuracy: 0.0102 - val_loss: 0.5362\n",
      "Epoch 72/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5095 - val_accuracy: 0.0102 - val_loss: 0.5394\n",
      "Epoch 73/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5114 - val_accuracy: 0.0102 - val_loss: 0.5368\n",
      "Epoch 74/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5155 - val_accuracy: 0.0102 - val_loss: 0.5352\n",
      "Epoch 75/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5069 - val_accuracy: 0.0102 - val_loss: 0.5337\n",
      "Epoch 76/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5076 - val_accuracy: 0.0102 - val_loss: 0.5338\n",
      "Epoch 77/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5056 - val_accuracy: 0.0102 - val_loss: 0.5374\n",
      "Epoch 78/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5102 - val_accuracy: 0.0102 - val_loss: 0.5405\n",
      "Epoch 79/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5167 - val_accuracy: 0.0102 - val_loss: 0.5396\n",
      "Epoch 80/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0094 - loss: 0.5093 - val_accuracy: 0.0102 - val_loss: 0.5369\n",
      "Epoch 81/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5122 - val_accuracy: 0.0102 - val_loss: 0.5319\n",
      "Epoch 82/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5073 - val_accuracy: 0.0102 - val_loss: 0.5348\n",
      "Epoch 83/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5074 - val_accuracy: 0.0102 - val_loss: 0.5494\n",
      "Epoch 84/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.5085 - val_accuracy: 0.0102 - val_loss: 0.5407\n",
      "Epoch 85/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0094 - loss: 0.5084 - val_accuracy: 0.0102 - val_loss: 0.5417\n",
      "Epoch 86/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0094 - loss: 0.5054 - val_accuracy: 0.0102 - val_loss: 0.5336\n",
      "Epoch 87/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0094 - loss: 0.5056 - val_accuracy: 0.0102 - val_loss: 0.5374\n",
      "Epoch 88/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0094 - loss: 0.5075 - val_accuracy: 0.0102 - val_loss: 0.5419\n",
      "Epoch 89/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0094 - loss: 0.5070 - val_accuracy: 0.0102 - val_loss: 0.5339\n",
      "Epoch 90/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0094 - loss: 0.5090 - val_accuracy: 0.0102 - val_loss: 0.5361\n",
      "Epoch 91/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0094 - loss: 0.5085 - val_accuracy: 0.0102 - val_loss: 0.5338\n",
      "Epoch 92/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0094 - loss: 0.5084 - val_accuracy: 0.0102 - val_loss: 0.5507\n",
      "Epoch 93/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0094 - loss: 0.5069 - val_accuracy: 0.0102 - val_loss: 0.5345\n",
      "Epoch 94/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0094 - loss: 0.5049 - val_accuracy: 0.0102 - val_loss: 0.5358\n",
      "Epoch 95/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0094 - loss: 0.5055 - val_accuracy: 0.0102 - val_loss: 0.5306\n",
      "Epoch 96/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0094 - loss: 0.5039 - val_accuracy: 0.0102 - val_loss: 0.5401\n",
      "Epoch 97/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0094 - loss: 0.5033 - val_accuracy: 0.0102 - val_loss: 0.5376\n",
      "Epoch 98/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5022 - val_accuracy: 0.0102 - val_loss: 0.5343\n",
      "Epoch 99/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5012 - val_accuracy: 0.0102 - val_loss: 0.5408\n",
      "Epoch 100/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5042 - val_accuracy: 0.0102 - val_loss: 0.5425\n",
      "Epoch 101/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5116 - val_accuracy: 0.0102 - val_loss: 0.5306\n",
      "Epoch 102/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5070 - val_accuracy: 0.0102 - val_loss: 0.5340\n",
      "Epoch 103/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5049 - val_accuracy: 0.0102 - val_loss: 0.5343\n",
      "Epoch 104/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5062 - val_accuracy: 0.0102 - val_loss: 0.5393\n",
      "Epoch 105/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5034 - val_accuracy: 0.0102 - val_loss: 0.5364\n",
      "Epoch 106/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0094 - loss: 0.5037 - val_accuracy: 0.0102 - val_loss: 0.5403\n",
      "Epoch 107/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5027 - val_accuracy: 0.0102 - val_loss: 0.5340\n",
      "Epoch 108/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5014 - val_accuracy: 0.0102 - val_loss: 0.5371\n",
      "Epoch 109/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0094 - loss: 0.5055 - val_accuracy: 0.0102 - val_loss: 0.5303\n",
      "Epoch 110/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5047 - val_accuracy: 0.0102 - val_loss: 0.5467\n",
      "Epoch 111/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5054 - val_accuracy: 0.0102 - val_loss: 0.5342\n",
      "Epoch 112/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5048 - val_accuracy: 0.0102 - val_loss: 0.5377\n",
      "Epoch 113/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5013 - val_accuracy: 0.0102 - val_loss: 0.5377\n",
      "Epoch 114/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5036 - val_accuracy: 0.0102 - val_loss: 0.5351\n",
      "Epoch 115/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5016 - val_accuracy: 0.0102 - val_loss: 0.5324\n",
      "Epoch 116/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5052 - val_accuracy: 0.0102 - val_loss: 0.5363\n",
      "Epoch 117/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5065 - val_accuracy: 0.0102 - val_loss: 0.5412\n",
      "Epoch 118/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5058 - val_accuracy: 0.0102 - val_loss: 0.5338\n",
      "Epoch 119/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5017 - val_accuracy: 0.0102 - val_loss: 0.5320\n",
      "Epoch 120/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0094 - loss: 0.5018 - val_accuracy: 0.0102 - val_loss: 0.5390\n",
      "Epoch 121/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5036 - val_accuracy: 0.0102 - val_loss: 0.5299\n",
      "Epoch 122/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5026 - val_accuracy: 0.0102 - val_loss: 0.5300\n",
      "Epoch 123/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5038 - val_accuracy: 0.0102 - val_loss: 0.5317\n",
      "Epoch 124/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4994 - val_accuracy: 0.0102 - val_loss: 0.5329\n",
      "Epoch 125/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.5024 - val_accuracy: 0.0102 - val_loss: 0.5344\n",
      "Epoch 126/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5018 - val_accuracy: 0.0102 - val_loss: 0.5365\n",
      "Epoch 127/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4990 - val_accuracy: 0.0102 - val_loss: 0.5353\n",
      "Epoch 128/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.5005 - val_accuracy: 0.0102 - val_loss: 0.5354\n",
      "Epoch 129/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0094 - loss: 0.5003 - val_accuracy: 0.0102 - val_loss: 0.5454\n",
      "Epoch 130/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5001 - val_accuracy: 0.0102 - val_loss: 0.5306\n",
      "Epoch 131/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5006 - val_accuracy: 0.0102 - val_loss: 0.5324\n",
      "Epoch 132/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4984 - val_accuracy: 0.0102 - val_loss: 0.5315\n",
      "Epoch 133/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0094 - loss: 0.4993 - val_accuracy: 0.0102 - val_loss: 0.5430\n",
      "Epoch 134/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5017 - val_accuracy: 0.0102 - val_loss: 0.5377\n",
      "Epoch 135/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5009 - val_accuracy: 0.0102 - val_loss: 0.5334\n",
      "Epoch 136/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.5047 - val_accuracy: 0.0102 - val_loss: 0.5382\n",
      "Epoch 137/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.5021 - val_accuracy: 0.0102 - val_loss: 0.5313\n",
      "Epoch 138/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.4967 - val_accuracy: 0.0102 - val_loss: 0.5464\n",
      "Epoch 139/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5019 - val_accuracy: 0.0102 - val_loss: 0.5328\n",
      "Epoch 140/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0094 - loss: 0.4985 - val_accuracy: 0.0102 - val_loss: 0.5387\n",
      "Epoch 141/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0094 - loss: 0.4989 - val_accuracy: 0.0102 - val_loss: 0.5382\n",
      "Epoch 142/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5020 - val_accuracy: 0.0102 - val_loss: 0.5294\n",
      "Epoch 143/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4989 - val_accuracy: 0.0102 - val_loss: 0.5331\n",
      "Epoch 144/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5015 - val_accuracy: 0.0102 - val_loss: 0.5353\n",
      "Epoch 145/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5008 - val_accuracy: 0.0102 - val_loss: 0.5348\n",
      "Epoch 146/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4966 - val_accuracy: 0.0102 - val_loss: 0.5281\n",
      "Epoch 147/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.5006 - val_accuracy: 0.0102 - val_loss: 0.5323\n",
      "Epoch 148/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.5043 - val_accuracy: 0.0102 - val_loss: 0.5315\n",
      "Epoch 149/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.5017 - val_accuracy: 0.0102 - val_loss: 0.5280\n",
      "Epoch 150/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.4986 - val_accuracy: 0.0102 - val_loss: 0.5372\n",
      "Epoch 151/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.5000 - val_accuracy: 0.0102 - val_loss: 0.5300\n",
      "Epoch 152/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4979 - val_accuracy: 0.0102 - val_loss: 0.5269\n",
      "Epoch 153/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4996 - val_accuracy: 0.0102 - val_loss: 0.5340\n",
      "Epoch 154/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4966 - val_accuracy: 0.0102 - val_loss: 0.5317\n",
      "Epoch 155/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4946 - val_accuracy: 0.0102 - val_loss: 0.5265\n",
      "Epoch 156/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.4949 - val_accuracy: 0.0102 - val_loss: 0.5337\n",
      "Epoch 157/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.4966 - val_accuracy: 0.0102 - val_loss: 0.5259\n",
      "Epoch 158/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.5023 - val_accuracy: 0.0102 - val_loss: 0.5363\n",
      "Epoch 159/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5016 - val_accuracy: 0.0102 - val_loss: 0.5270\n",
      "Epoch 160/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4955 - val_accuracy: 0.0102 - val_loss: 0.5261\n",
      "Epoch 161/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.4979 - val_accuracy: 0.0102 - val_loss: 0.5481\n",
      "Epoch 162/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4978 - val_accuracy: 0.0102 - val_loss: 0.5313\n",
      "Epoch 163/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0094 - loss: 0.4944 - val_accuracy: 0.0102 - val_loss: 0.5289\n",
      "Epoch 164/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0094 - loss: 0.4968 - val_accuracy: 0.0102 - val_loss: 0.5298\n",
      "Epoch 165/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.5009 - val_accuracy: 0.0102 - val_loss: 0.5297\n",
      "Epoch 166/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.5016 - val_accuracy: 0.0102 - val_loss: 0.5247\n",
      "Epoch 167/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0094 - loss: 0.4972 - val_accuracy: 0.0102 - val_loss: 0.5360\n",
      "Epoch 168/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4941 - val_accuracy: 0.0102 - val_loss: 0.5223\n",
      "Epoch 169/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4939 - val_accuracy: 0.0102 - val_loss: 0.5296\n",
      "Epoch 170/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.4959 - val_accuracy: 0.0102 - val_loss: 0.5262\n",
      "Epoch 171/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4933 - val_accuracy: 0.0102 - val_loss: 0.5248\n",
      "Epoch 172/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4945 - val_accuracy: 0.0102 - val_loss: 0.5265\n",
      "Epoch 173/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.4952 - val_accuracy: 0.0102 - val_loss: 0.5275\n",
      "Epoch 174/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4941 - val_accuracy: 0.0102 - val_loss: 0.5344\n",
      "Epoch 175/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.4959 - val_accuracy: 0.0102 - val_loss: 0.5275\n",
      "Epoch 176/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.4928 - val_accuracy: 0.0102 - val_loss: 0.5255\n",
      "Epoch 177/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4935 - val_accuracy: 0.0102 - val_loss: 0.5236\n",
      "Epoch 178/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4925 - val_accuracy: 0.0102 - val_loss: 0.5258\n",
      "Epoch 179/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4921 - val_accuracy: 0.0102 - val_loss: 0.5281\n",
      "Epoch 180/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4915 - val_accuracy: 0.0102 - val_loss: 0.5255\n",
      "Epoch 181/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4915 - val_accuracy: 0.0102 - val_loss: 0.5255\n",
      "Epoch 182/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.4920 - val_accuracy: 0.0102 - val_loss: 0.5241\n",
      "Epoch 183/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4959 - val_accuracy: 0.0102 - val_loss: 0.5257\n",
      "Epoch 184/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.5013 - val_accuracy: 0.0102 - val_loss: 0.5186\n",
      "Epoch 185/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4919 - val_accuracy: 0.0102 - val_loss: 0.5240\n",
      "Epoch 186/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4900 - val_accuracy: 0.0102 - val_loss: 0.5268\n",
      "Epoch 187/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.4931 - val_accuracy: 0.0102 - val_loss: 0.5215\n",
      "Epoch 188/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.4906 - val_accuracy: 0.0102 - val_loss: 0.5216\n",
      "Epoch 189/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0094 - loss: 0.4934 - val_accuracy: 0.0102 - val_loss: 0.5261\n",
      "Epoch 190/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.4937 - val_accuracy: 0.0102 - val_loss: 0.5210\n",
      "Epoch 191/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.4895 - val_accuracy: 0.0102 - val_loss: 0.5287\n",
      "Epoch 192/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.4902 - val_accuracy: 0.0102 - val_loss: 0.5213\n",
      "Epoch 193/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.4899 - val_accuracy: 0.0102 - val_loss: 0.5255\n",
      "Epoch 194/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4958 - val_accuracy: 0.0102 - val_loss: 0.5259\n",
      "Epoch 195/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0094 - loss: 0.4960 - val_accuracy: 0.0102 - val_loss: 0.5242\n",
      "Epoch 196/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0094 - loss: 0.4936 - val_accuracy: 0.0102 - val_loss: 0.5194\n",
      "Epoch 197/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.4942 - val_accuracy: 0.0102 - val_loss: 0.5406\n",
      "Epoch 198/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0094 - loss: 0.4931 - val_accuracy: 0.0102 - val_loss: 0.5207\n",
      "Epoch 199/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0094 - loss: 0.4962 - val_accuracy: 0.0102 - val_loss: 0.5291\n",
      "Epoch 200/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0094 - loss: 0.4944 - val_accuracy: 0.0102 - val_loss: 0.5259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24f0df5d880>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train2, y_train2, epochs=iterations, validation_split=0.05, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40eef300-0aa6-4982-8d70-9f7c9725771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "445\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model.predict(x_test2)\n",
    "print(len(predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d34c6f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With  20 neurons per layer,  5 layers, and  200 iterations\n",
      "using the training set slice(600, -1, None)\n",
      "47.640449438202246 percent of the ages are good\n",
      "52.359550561797754 percent of the ages are bad\n"
     ]
    }
   ],
   "source": [
    "metric2=0.3 #is the accuracy better than 30%?\n",
    "goodfit2=np.where(((1-metric2) < predictions2/y_test2) & ((1+metric2) > predictions2/y_test2)) \n",
    "badfit2=np.where(((1-metric2) > predictions2/y_test2) | ((1+metric2) < predictions2/y_test2))\n",
    "\n",
    "print ('With ', neurons_per_layer, 'neurons per layer, ', layers, 'layers, and ', iterations, 'iterations')\n",
    "print ('using the training set', trainbin)\n",
    "print (len(goodfit2[0])/len(y_test2)*100, 'percent of the ages are good')\n",
    "print (len(badfit2[0])/len(y_test2)*100, 'percent of the ages are bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e203510c-d93e-49b0-82f1-e6cb7b251417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425631\n",
      "\u001b[1m13301/13301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "DR19x2 = np.dstack([data_masked['teff'],data_masked['logg'], data_masked['m_h_atm'],\n",
    "                   data_masked['alpha_m_atm'], data_masked['c_h'], data_masked['n_h']])[0]\n",
    "print(len(data_masked['teff']))\n",
    "\n",
    "DR19x2= DR19x2/scaling_x2\n",
    "predictionsDR19_2 = model.predict(DR19x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c82f539-21c2-4d83-a2bb-ff8aaccbba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Pulling Labels and Data\n",
    "apokasc2_age = predictionsDR19.flatten() * scaling_y\n",
    "apok2_age = predictionsDR19_2.flatten() * scaling_y2\n",
    "age_difference = apok2_age - apokasc2_age\n",
    "star_ids = data_masked['tic_v8_id']\n",
    "#Creating DataFrame of the results\n",
    "dataframe = pd.DataFrame({\n",
    "\t\"TIC\": star_ids,\n",
    "\t'APOK2_predicted_Gyr': apok2_age,\n",
    "\t'APOKASC2_predicted_Gyr': apokasc2_age,\n",
    "    'APOK2_APOKASC2_Diff': age_difference\n",
    "})\n",
    "#Saving DataFrame to CSV\n",
    "dataframe.to_csv('APOK2_APOKASC2_Comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99d43871-b400-4d2c-8dc3-8dfca1296571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference between data set is: 5.5876219185966\n"
     ]
    }
   ],
   "source": [
    "print(f'Average difference between data set is:', np.mean(age_difference))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
